[
  {
    "objectID": "Zahid-blog.html",
    "href": "Zahid-blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog\nMy blog on various issues including posts with R codes."
  },
  {
    "objectID": "posts/youth_bulge_pol_stability/index.html",
    "href": "posts/youth_bulge_pol_stability/index.html",
    "title": "Political stability and youth bulge",
    "section": "",
    "text": "Young population: boon or bane\nWhether a young population is a boon or a bane for a society depends on a number of factors, including the level of economic development, the quality of governance, and the degree of social and political inclusion. On the one hand, a young population can be a boon for a society in many ways as young and educated population can contribute to economic growth, innovation, social change, and cultural vibrancy. Click here to read more\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Qualitative and Quantitative Data Analysis/index.html",
    "href": "posts/Qualitative and Quantitative Data Analysis/index.html",
    "title": "Mixed methods research (HSF fellows)",
    "section": "",
    "text": "Mixed methods reseach tools\nMy talk on Qualitative and Quantitative Data Analysis for Political\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Mental Junk Food: Bullshit Superspreader",
    "section": "",
    "text": "What is mental junk food? How does it spread misinformation/disinformation? What skills are required to spot and call bullshit? These are important questions for all of us to ponder about for self-awareness and helping society to differentiate between misinformation/disinformation and facts.\nWe have been warned by junk food for decades to maintain our physical health, and medical doctors always emphasize on using simple food. Junk food is tasty and enjoyable in the moment but lacks nutritional value and can be detrimental to health over time. But there is little talk about mental junk food. Mental junk food refers to content, activities, or behaviours that intellectually or emotionally unfulfilling, often providing short-term pleasure of distraction, but lacking in depth, meaning, or substance. Such activities may engage one with minimum effort and provide entertainment and keep one engaged for hours due to retention algorithms designed by social media giants. \nA country like Pakistan where consuming too much junk food has yet not been the norm as most of its population can’t afford. But mental junk food is cheap and easily accessible, therefore, a large population is consuming excessive mental junk food which has very detrimental effects on personal well-being, society, family and community. Pakistan has very low literacy rate and digital literacy rate is almost non-existent, so  differentiating between propaganda and facts is difficult to identify.  This has made things worse in terms of having meaningful dialogue and argument on any major issue of national or regional importance. This mounting pressure of social media puts undue pressure on governments, bureaucracy, organizations and even judiciary. As a result, there is high probability that right decision making is compromised.\nPoliticians, media, science, academia, policy makers, start ups among others are engaged in spreading/rewarding misinformation/disinformation over analytics. Each of us, even if few of us knows its misinformation/disinformation, contribute to its share.\nBullshit comes in the form of rhetoric or fancy language, what we call old-school bullshit. Politicians, media, science, academia, policy makers , start ups and many others are engaged in spreading/rewarding  misinformation/disinformation/propaganda over analytics. New propaganda strategy is to use data based analysis which becomes difficult to refute due to lack of knowledge about those sophisticated tools. Even though each of us knows this is bullshit but we all contribute to its share.\nPeople don’t have time but have smartphones to spread bullshit. Despite the fact that one can easily check facts due to technology available in one’s hand, bullshit goes largely unchallenged. Technology has made bullshit worse. To get quality information, we face the temptation to click on the informational equivalent of empty calories, the mental junk food usually wins. Click-driven media and the most successful headlines don’t convey facts, they promise an emotional experience. Fluffy and glitter overtaken in depth thoughtful content. Media is busy in keeping people engaged instead of keeping them informed.\nBullshit has been prevailing for millions of years even among animals according to scientific research, but it has become more rapid due to low cost of spreading information. Access to internet has made it easy to spread whatever one likes. Today anyone with one’s personal computer and internet connection can produce professional-looking document and distribute them around the world without cost. All this can be done their pyjamas.\nThis easy and almost free creation of the mindless lists, quizzes, memes, misinformation about scientific findings and celebrity gossip that proliferate social media have diverted us from thoughtful analyses of the sort one used to see in the leading daily print media.\nSocial media has firehouse strategy, our trust in friends and institutions erode. Gary Kasparov Russian chess grandmaster summarized this approach in a post on Twitter: “The point of modern propaganda isn’t only to misinform or push an agenda, It is to exhaust your critical thinking, to annihilate truth.”  Prior to the Internet, news papers, periodical made money by selling subscriptions and cared about quality of information a source provided, its accuracy, and its relevance to your daily life. To attract subscribers and retain them, publishers provided novel and well-vetted information. In this digital era, being careful is admirable but it does not sell ads. Social media is fertile ground for disinformation. Incentives are to spread information without worrying about its content.\nSatirist Jonathan Swift wrote in 1710 that “falsehood flies, and truth comes limping after it.”\nOne can summarize it as :\ni) misinformation/disinformation takes less work to create than to clean up,\nii) takes less intelligence to create than to clean up, and\niii) spreads faster than efforts to clean it up.\nHow to spot and call misinformation/disinformation/falsehood in this environment.  Spotting bullshit is tantamount to walking around at night where we are aware of our surroundings and alert for signs of danger. We must learn how to question the source of information. Who is telling us all this? How does he or she know it? What is this person trying to sell us?  There is an urgent need to work on digital literacy not only among the masses but among the educated one so that they can spot and call bullshit. Spotting bullshit is important for an individual to know about it while calling bullshit is more important as it means conveying others about the same bullshit.\nNote: Word “Bullshit” is used in the context of lie, invention, falsehood, untruth, propaganda, misinformation, fabrication, white lie, half-truth, a tissue of lies, fairy tale without any offense.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Higher_education/index.html",
    "href": "posts/Higher_education/index.html",
    "title": "Virtual Learning: A WayForward for Higher Education",
    "section": "",
    "text": "Pakistani universities were mainly launched as teaching institutions like many colleges in the United States in the 19th century. There were limited research programs. Later, research element was introduced with a focus on quantity and achievement of certain metrics. As a result, more faculty and staff were recruited besides adding many bureaucratic staff in the name of quality enhancement, commercialization of research, and creating an imbalance in the faculty pyramid among many others. Most of these administrative jobs were created in the name of improving quality of research.\nPension, salaries, and many other expenditures besides having more staff have increased manifold over time. Successive governments have not increased financing of the universities proportionate to their budgetary requirements. Universities are hard pressed to use the instrument of increasing fee and increasing enrolment without any concern for the quality."
  },
  {
    "objectID": "posts/Higher_education/index.html#business-as-usual",
    "href": "posts/Higher_education/index.html#business-as-usual",
    "title": "Virtual Learning: A WayForward for Higher Education",
    "section": "Business as Usual",
    "text": "Business as Usual\n\n\n\n\n\n\n\n\n\nQuestion is how long this business-as-usual (BAU) approach will allow universities put extra burden on students’ parent pockets. Parents are already facing economic miseries due to high inflation and limited earning opportunities. What are possible solutions and way-forward. This requires serious introspection and integrated thinking for reimagining higher education in the third decade of the 21st century.\n\n\n\n\nScaling and Developing Learning Outcome Ecosystem\nWorld has gone digital and covid-19 pandemic has exposed the globe for online learning and Pakistan too have remained in this phase for two years. So digital emersion can help universities to come out of not only financial crisis but also can play an effective role in reaching those who have been unserved so far either due to financial constraints or limited enrollment capacity of the universities.\n\n\n\n Moreover, it will help millions of Pakistanis to benefit from reputed Professors who are currently accessible to a privileged 100 or students per year. On one hand, Covid-19 pandemic has disrupted the entire traditional education system across the globe. But simultaneously it has opened many new opportunities to have tertiary education accessible to masses which was not possible before covid-19 pandemic. Cost of tertiary education is very high and has also limited capacity for scaling at large scale. But post-Covid-19 pandemic era has made it possible to provide tertiary education to most if not all at very affordable cost besides provision of flexible learning opportunities so that no one is left behind.\nChange is already here. Technological companies like Amazon, Google, Microsoft, all are offering their own badges, certificates, and credentials. Though these are for entry level jobs, gradually these companies will move up the educational food chain. These companies already carry an advantage of being operating at scale.\nOnline learning is different than distance learning and those who express their reservations about online learning and prefer physical learning basically confuse “Learning” and “Time”. Their focus is on “Time” as fixed variable while “Learning” as a variable. But the concept of making “Learning” as fixed and “Time” as variable can make both online learning equally or even more useful than physical learning. While both can be good or bad in routine. Don’t proponents of physical learning think that delivering a lecture to 40 to 50 students for three hours in one go per week and expecting students to grasp all the stuff is not a workable idea. Virtual learning mode with competency-based learning not only provides live lecture but also opportunity to understand it after the class.\nSecondly, virtual, and online learning mode will not only help to have more enrollment but also significant reduction in cost of delivery of lecturing. To have experiential learning, there can be gradual shift towards this online learning and initially general courses can be offered by Pakistani leading scholars in the field across the country. If one fourth or one fifth courses can be offered through virtual mode with Pakistan leading scholars at the first stage, it will immensely benefit all stakeholders- students, universities and higher education management. To overcome the fear of cheating, exams can be conducted at respective departments. This will not only reduce financial burden on universities’ exchequer but also help students to learn from scholars of international repute instead of each batch of forty to fifty students getting different quality education from part time teachers. This financial cushion maybe utilized for research and providing fee concessions to students.\nIf post-Covid online learning opportunity will not be utilized, future of universities will become highly uncertain. All public sector universities are in serious financial crisis and are unable to spare money for research and development as these are already short of paying their salaries, pensions, and utilities. How long will universities survive on this ever-increasing deficit model? How long one can resist for not adapting oneself to changing circumstances? What level of compromise on quality of soft and hard infrastructure universities will afford?\nScaling of higher education through digital and online learning platform will be a win-win situation both for the universities and society. There will be new forms of content delivery, new ways to access learning, and new ways to certify that a learner has mastered various concepts. Above all, online platforms are one of the main tools for reaching the unreachable.\nBusiness as usual will not help to resolve universities’ financial issues even if there is some budget increase by the government which is a remote possibility in the next couple of years due to national and international economic concerns. Our universities’ financial viability depends how diligently we work on finding solutions to our problems by ourselves instead of getting some consultants and managing some aid to overcome crisis for the time being."
  },
  {
    "objectID": "posts/Higher_education/index.html#scaling-and-developing-learning-outcome-ecosystem",
    "href": "posts/Higher_education/index.html#scaling-and-developing-learning-outcome-ecosystem",
    "title": "Virtual Learning: A WayForward for Higher Education",
    "section": "Scaling and Developing Learning Outcome Ecosystem",
    "text": "Scaling and Developing Learning Outcome Ecosystem\nWorld has gone digital and covid-19 pandemic has exposed the globe for online learning and Pakistan too have remained in this phase for two years. So digital emersion can help universities to come out of not only financial crisis but also can play an effective role in reaching those who have been unserved so far either due to financial constraints or limited enrollment capacity of the universities."
  },
  {
    "objectID": "posts/export_import_analysis_south_asia/index.html",
    "href": "posts/export_import_analysis_south_asia/index.html",
    "title": "Export and Import Trends in South Asia: A Comparative Analysis",
    "section": "",
    "text": "Export and Import Trends in South Asia: A Comparative Analysis\nIn this post, I will examine India, Pakistan, Sri Lanka, and Bangladesh exports and imports from 1980 to 2023. Exports are a crucial indicator of a country’s competitiveness in the global market, while imports reflect the level of consumption and dependence on foreign goods and services. A healthy economy often features high exports supporting its imports, signifying robust economic growth. Additionally, I will include an analysis of exports per capita, which provides a more granular view of economic performance by reflecting the average export value per person. I will also delve into how Pakistan’s performance in terms of exports and imports as a percentage of GDP and exports per capita compared to that of India, Sri Lanka, and Bangladesh. Click here to read more\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/data-government analytics/index.html",
    "href": "posts/data-government analytics/index.html",
    "title": "Harnessing Data Analytics for Effective Governance in Pakistan: A Support, Not a Substitute",
    "section": "",
    "text": "Harnessing Data Analytics for Effective Governance in Pakistan: A Support, Not a Substitute\nGiven the intricate challenges confronting Pakistan, a nation with a population of two hundred and forty million, in the third decade of the 21st century, it is imperative to establish robust government analytics to enhance decision-making processes for senior leadership and bureaucracy. In today’s digital age, societal expectations are heightened, while government resources remain limited. Consequently, maximizing the efficiency of these resources is paramount in addressing development and other challenges. Data analytics provides a means for thorough examination and holistic understanding of issues, enabling governments to better cope with these challenges. As governments expand their scope of operations to cater to the needs of the masses, there is a growing need to bolster their capacity to measure and evaluate a wide array of activities. In the digital age, developing the capability to obtain, interpret, and efficiently employ data for informed decision-making is crucial for attaining developmental objectives. Early investment in data-driven policies is vital to maximize the use of resources and promptly pursue desired outcomes. The granularity of data will offer profound insights, enhancing the effectiveness of decision-making processes.\nIn our pursuit of a better future, it is important to not only focus on having the right data but also to make sense of complex information for public policy making to supplement/complement public policy making. Data analytics based on various data sources of data: administrative, public procurement, health, education, public sector development projects, and budget spending through visualization, automated reproducible reports, statistical analysis, program evaluation, and trend analysis is the need of the hour. Besides this empirical data analysis, text analysis of policy documents, regulations, and tenders based on topic modeling and policy focus using Machine Learning tools is also needed.\nThe private sector has utilized the full potential of data. Nonetheless, the public sector operates under distinct dynamics compared to the private sector, despite the significant benefits that data has brought to the latter. Therefore, it’s important to understand that it is not the case that everything is measurable or that everything which is measurable is of great importance for public policy. Secondly, it is not data but data that matters. Easy-to-measure indicators may lead to false alarms leaving real issues unattended. It is also needed to protect space for judgment, discretion, and deliberation because not everything that matters can be measured.\nMy philosophy is that measuring what matters is more important rather than working on what is measurable. Secondly, what analytics can do is strengthen the quality of conversations about how to improve public administration, rather than dictating managerial responses to specific analytics findings.\nAnalytics, in my opinion, should supplement/complement decision making of senior leadership and senior government officials’ practical and tacit knowledge. Data analytics can strengthen the quality of conversation about how to improve public administration, rather than forcing to adapt specific analytics findings. It will generate evidence for better conversation and thus decisions- about how to improve public administration, execute projects efficiently and effectively, how to monitor and evaluate different projects among many other things.\nAreas Needing Focus\nJustice: Using data to identify inefficiencies in the judicial process and recommend reforms.\nGovernance and Climate Change: Establishing links between governance practices and climate change mitigation and adaptation.\nInstitution Building: Strengthening public institutions by identifying weaknesses through data and proposing targeted improvements.\nPublic Procurement: Developing clear rules for procurement officers based on data to ensure better policy outcomes.\nMy vision for data analytics is rooted in the pursuit of a brighter future, where I prioritize not only acquiring the right data but also harnessing the power of complex information to enhance public policy making. I recognize the imperative need for data analytics across various sources such as administrative records, public procurement data, health and education statistics, and public sector development projects. Through visualization, automated reproducible reports, statistical analysis, program evaluation, and trend analysis, I aim to extract valuable insights that can inform and complement public policy decisions.\nIn addition to empirical data analysis, I understand the significance of text analysis of policy documents, regulations, and tenders using techniques such as topic modeling and machine learning. This comprehensive approach allows me to uncover hidden patterns, identify policy focus areas, and enhance decision-making processes.\nHowever, I acknowledge that the public sector operates under unique dynamics compared to the private sector. Therefore, I emphasize the importance of understanding that not everything is measurable, and I prioritize measuring what truly matters. My philosophy revolves around supplementing decision-making processes with data analytics while acknowledging the invaluable practical and tacit knowledge of senior leadership and government officials.\nBy integrating data analytics into decision-making processes, I aim to facilitate better conversations about improving public administration, project execution efficiency, monitoring and evaluation, and various other aspects of governance. Ultimately, my goal is to generate evidence that enhances the quality of decision-making and fosters continuous improvement in public administration practices.\nLeveraging the Data Revolution for Public Sector Benefit\nThe data revolution has immensely benefited the private sector, and the public sector has yet to fully realize these benefits. It is important to harness the power of high-quality data and government analytics to derive informed public policy, laying the foundation for effective governance in our data-driven world. This requires human capital in data analytics and data science to supplement/complement bureaucracy-backed public policies. As creative bureaucracy is a basic pillar of executing any government policies and has deep insight, there is a need to enhance their capacity to make the right sense of data from complex information.\nMy vision is to harness the power of high-quality data analytics to drive informed public policy, laying the groundwork for effective governance in our data-driven world. Recognizing data as the new oil, I understand its immense value in navigating the complexities of modern society and gaining evidence-based insights into pressing issues.\nAligned with my commitment to the Sustainable Development Goals (SDGs), I recognize the urgent need for comprehensive, accurate, disaggregated, and timely data. By leveraging data analytics, I aim to inform policy decisions, guide resource allocation, and ensure that interventions are precisely tailored to drive impactful progress towards sustainable development.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "myR.html",
    "href": "myR.html",
    "title": "Talks,trainigs,others",
    "section": "",
    "text": "While I regularly conduct trainings, occasionally writes in detail about use of data basics using R and deliver seminars. Some of these posts for start learning R are given here.\n\n\n\n\n\n\nTip\n\n\n\nYou can find my github code repository for my codes here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Data from PDFs documents using tabulapdf in R\n\n\nPart 1\n\n\n\n\n\n\n\n\nJun 9, 2024\n\n\nMuhammad Yaseen, Zahid Asghar\n\n\n\n\n\n\n\n\n\n\n\n\nExtracting Data from PDFs documents using tabulapdf in R\n\n\nPart 2\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n\nMuhammad Yaseen, Zahid Asghar\n\n\n\n\n\n\n\n\n\n\n\n\nHarnessing Data Analytics for Effective Governance in Pakistan: A Support, Not a Substitute\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n\nZahid Asghar\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "myR/pdf_tables/index.html#introduction",
    "href": "myR/pdf_tables/index.html#introduction",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, we will explore how to extract data from PDF files using the tabulapdf package in R. PDF is a common file format for sharing data, but extracting structured data from PDFs can be challenging. The tabulapdf package provides an easy way to extract tables from PDFs and convert them into a usable format."
  },
  {
    "objectID": "myR/pdf_tables/index.html#importance-of-extracting-data-from-pdfs",
    "href": "myR/pdf_tables/index.html#importance-of-extracting-data-from-pdfs",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Importance of Extracting Data from PDFs",
    "text": "Importance of Extracting Data from PDFs\nExtracting tables from PDF files is crucial for several reasons:\n\n\nData Accessibility: Many important documents and reports are shared in PDF format. Extracting data from these documents makes it accessible for analysis and further use.\n\nAutomated Data Processing: Manual data entry from PDFs is time-consuming and prone to errors. Automated extraction ensures accuracy and efficiency.\n\nData Integration: Extracting data from PDFs allows for the integration of information from various sources, enhancing the comprehensiveness of data analysis.\n\nHistorical Data Analysis: Many historical documents are available only in PDF format. Extracting data from these PDFs allows for the analysis of trends over time.\n\nEnhanced Decision Making: Having access to data in an analyzable format helps in making informed decisions based on comprehensive data analysis.\n\nSo extracting tables from PDFs is a critical skill that enables access to important data, ensures accuracy, and saves time in data processing.We can automate the process and make the data extraction workflow more efficient. This not only improves productivity but also ensures that the data extracted is accurate and reliable, providing a solid foundation for any subsequent analysis or decision-making processes.\nGiven these reasons, it’s evident why efficient tools for extracting data from PDFs are invaluable. So lets learn how to extract data from PDFs using the tabulapdf package in R."
  },
  {
    "objectID": "myR/pdf_tables/index.html#required-libraries",
    "href": "myR/pdf_tables/index.html#required-libraries",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Required Libraries",
    "text": "Required Libraries\nI have tried tabulizer to install but not successful. I have come across tabulapdf package and find it very handy. To begin, we’ll need to install and load the necessary libraries. Here is the list of packages we’ll be using:\n\nrJava\ntabulapdf\npdftools\ntidyverse\n\nLet’s load these libraries in R.\n\nCodeSys.setenv(JAVA_HOME = \"C:/Program Files/Java/jdk-22\") ## One check is for one's system if required for running `rJava`\nlibrary(rJava)\nlibrary(tabulapdf)\nlibrary(pdftools)\nlibrary(tidyverse)"
  },
  {
    "objectID": "myR/pdf_tables/index.html#extracting-tables-from-a-pdf",
    "href": "myR/pdf_tables/index.html#extracting-tables-from-a-pdf",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Extracting Tables from a PDF",
    "text": "Extracting Tables from a PDF\nThe extract_tables function extracts tables from the specified page of the PDF file. In this case, we extracted the table from the first page of the sample PDF file.\nCodef2 &lt;- \"https://raw.githubusercontent.com/ropensci/tabulapdf/main/inst/examples/mtcars.pdf\"\n\nextract_tables(f2, pages = 1) \n\n\nTable 1: Extracted Table from the PDF\n\n\n[[1]]\n# A tibble: 5 × 12\n  model          mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Mazda RX4     21       6   160   110  3.9   2.62  16.5     0     1     4     4\n2 Mazda RX4 W…  21       6   160   110  3.9   2.88  17.0     0     1     4     4\n3 Datsun 710    22.8     4   108    93  3.85  2.32  18.6     1     1     4     1\n4 Hornet 4 Dr…  21.4     6   258   110  3.08  3.21  19.4     1     0     3     1\n5 Hornet Spor…  18.7     8   360   175  3.15  3.44  17.0     0     0     3     2\n\n\n\n\nTable 1 indicates that the table has been successfully extracted from the PDF file. We can now proceed to convert this table into a data frame for further analysis.\nNow we will extract a table from a specific page of another PDF file. This PDF is a monthly report on Consumer Price Index from the Pakistan Bureau of Statistics.\n\nCode# URL of the monthly review PDF\nf1 &lt;- \"https://www.pbs.gov.pk/sites/default/files/price_statistics/cpi/may/Monthly%20Review%20May%2C%202024.pdf\"\n\n\n\n\n\n\n\nFigure 1: General Inflation (%)\n\n\nOne can see from Figure 1 that the table we want to extract is on the third page of the PDF. Let’s extract the table from the third page of the PDF file.\nCode# Extract and view the table from the third page of the PDF\nextract_tables(f1, pages = 3)[[1]] |&gt; head()\n\n\nTable 2: Extracted Table from the PDF\n\n\n# A tibble: 6 × 7\n  `Table 1.a` ...2      ...3      General Inflation (%)(Base…¹ ...5  ...6  ...7 \n  &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;                        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 &lt;NA&gt;        &lt;NA&gt;      &lt;NA&gt;      CPI                          &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 &lt;NA&gt;        &lt;NA&gt;      General   Food                         Non-… SPI** WPI  \n3 PERIOD      National  Urban     Rural Urban Rural            Urba… &lt;NA&gt;  &lt;NA&gt; \n4 &lt;NA&gt;        YoY MoM   YoY MoM   YoY MoM YoY MoM YoY MoM      YoY … YoY … YoY …\n5 Aug-22      27.3 2.4  26.2 2.6  28.8 2.2 28.8 1.6 30.2 1.2   24.7… 34.0… 41.2…\n6 Sep-22      23.2 -1.2 21.2 -2.1 26.1 0.2 30.8 5.2 32.7 5.7   15.2… 28.6… 38.9…\n# ℹ abbreviated name: ¹​`General Inflation (%)(Base 2015-16)`\n\n\n\n\nTable 2 indicates that the table has been successfully extracted from the PDF file. We can now proceed to convert this table into a data frame for further analysis."
  },
  {
    "objectID": "myR/pdf_tables/index.html#converting-extracted-table-to-data-frame",
    "href": "myR/pdf_tables/index.html#converting-extracted-table-to-data-frame",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Converting Extracted Table to Data Frame",
    "text": "Converting Extracted Table to Data Frame\nAfter extracting the table, we need to convert it into a data frame and clean the data for further analysis.\n\nCodetable &lt;- extract_tables(f1, pages = 3)[[1]]\n\n# Convert the extracted table to a data frame\ntable_df &lt;- as.data.frame(table)\n\n# Skip the first four rows\ntable_filtered &lt;- table_df %&gt;% slice(-(1:4))\n\n# Combine the rows into a single text string\ntable_text &lt;- apply(table_filtered, 1, paste, collapse = \" \")\n\n# Split the text into columns\ntable_separated &lt;- str_split_fixed(table_text, \"\\\\s+\", n = 19)  # Adjust 'n' based on the number of columns\n\n# Convert the separated text into a data frame\ntable_separated_df &lt;- as.data.frame(table_separated)"
  },
  {
    "objectID": "myR/pdf_tables/index.html#renaming-columns",
    "href": "myR/pdf_tables/index.html#renaming-columns",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Renaming Columns",
    "text": "Renaming Columns\nWe will now rename the columns to make the data more readable and meaningful.\n\nCode# Rename the columns of the data frame\ncolnames(table_separated_df) &lt;- c(\n  \"Period\", \n  \"CPI_general_yoy\", \"CPI_general_mom\", \n  \"CPI_general_yoy_urban\", \"CPI_general_mom_urban\", \n  \"CPI_general_yoy_rural\", \"CPI_general_mom_rural\", \n  \"CPI_food_yoy_urban\", \"CPI_food_mom_urban\", \n  \"CPI_food_yoy_rural\", \"CPI_food_mom_rural\", \n  \"CPI_non_food_yoy_urban\", \"CPI_non_food_mom_urban\", \n  \"CPI_non_food_yoy_rural\", \"CPI_non_food_mom_rural\", \n  \"SPI_yoy\", \"SPI_mom\", \n  \"WPI_yoy\", \"WPI_mom\"\n)"
  },
  {
    "objectID": "myR/pdf_tables/index.html#cleaned-data-frame",
    "href": "myR/pdf_tables/index.html#cleaned-data-frame",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Cleaned Data Frame",
    "text": "Cleaned Data Frame\n\nCodetable_separated_df |&gt; kableExtra::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeriod\nCPI_general_yoy\nCPI_general_mom\nCPI_general_yoy_urban\nCPI_general_mom_urban\nCPI_general_yoy_rural\nCPI_general_mom_rural\nCPI_food_yoy_urban\nCPI_food_mom_urban\nCPI_food_yoy_rural\nCPI_food_mom_rural\nCPI_non_food_yoy_urban\nCPI_non_food_mom_urban\nCPI_non_food_yoy_rural\nCPI_non_food_mom_rural\nSPI_yoy\nSPI_mom\nWPI_yoy\nWPI_mom\n\n\n\nAug-22\n27.3\n2.4\n26.2\n2.6\n28.8\n2.2\n28.8\n1.6\n30.2\n1.2\n24.7\n3.3\n27.5\n3.1\n34.0\n5.2\n41.2\n3.1\n\n\nSep-22\n23.2\n-1.2\n21.2\n-2.1\n26.1\n0.2\n30.8\n5.2\n32.7\n5.7\n15.2\n-6.6\n20.1\n-4.9\n28.6\n-1.4\n38.9\n1.4\n\n\nOct-22\n26.6\n4.7\n24.6\n4.5\n29.5\n5.0\n34.7\n4.5\n37.2\n6.1\n18.2\n4.5\n22.4\n3.9\n24.0\n-1.5\n32.6\n-0.5\n\n\nNov-22\n23.8\n0.8\n21.6\n0.4\n27.2\n1.3\n29.7\n0.0\n33.5\n0.5\n16.4\n0.6\n21.4\n2.1\n27.1\n6.1\n27.7\n0.0\n\n\nDec-22\n24.5\n0.5\n21.6\n0.3\n28.8\n0.7\n32.7\n0.0\n37.9\n0.1\n14.8\n0.6\n20.7\n1.4\n27.8\n0.2\n27.1\n-0.7\n\n\nJan-23\n27.6\n2.9\n24.4\n2.4\n32.3\n3.6\n39.0\n3.9\n45.2\n5.7\n15.6\n1.2\n20.9\n1.5\n30.5\n1.3\n28.5\n1.8\n\n\nFeb-23\n31.5\n4.3\n28.8\n4.5\n35.6\n4.0\n41.9\n4.3\n47.0\n3.9\n20.8\n4.7\n25.3\n4.1\n33.6\n3.7\n36.4\n8.2\n\n\nMar-23\n35.4\n3.7\n33.0\n3.9\n38.9\n3.5\n47.1\n5.6\n50.2\n4.5\n24.1\n2.7\n28.5\n2.4\n40.4\n5.8\n37.5\n4.7\n\n\nMay-23\n36.4\n2.4\n33.5\n2.0\n40.7\n3.0\n46.8\n3.4\n52.2\n4.2\n24.9\n1.0\n29.9\n1.6\n42.1\n2.7\n33.4\n0.1\n\n\nMay-23\n38.0\n1.6\n35.1\n1.5\n42.2\n1.7\n48.1\n1.9\n52.4\n1.4\n26.6\n1.2\n32.5\n2.0\n43.0\n1.3\n32.8\n1.0\n\n\nJun-23\n29.4\n-0.3\n27.3\n0.1\n32.4\n-0.8\n40.8\n0.1\n41.5\n-1.6\n18.7\n0.1\n23.8\n0.1\n34.9\n0.2\n22.4\n-0.3\n\n\nJul-23\n28.3\n3.5\n26.3\n3.6\n31.3\n3.3\n40.2\n3.7\n41.3\n3.5\n17.3\n3.5\n22.0\n3.0\n29.3\n2.8\n23.1\n2.5\n\n\nAug-23\n27.4\n1.7\n25.0\n1.6\n30.9\n1.9\n38.8\n0.6\n40.6\n0.8\n16.3\n2.4\n22.0\n3.1\n27.9\n4.1\n24.3\n4.2\n\n\nSep-23\n31.4\n2.0\n29.7\n1.7\n33.9\n2.5\n33.9\n1.5\n35.4\n1.8\n26.8\n1.8\n32.3\n3.2\n32.0\n1.7\n26.4\n3.1\n\n\nOct-23\n26.8\n1.0\n25.5\n1.1\n28.7\n0.9\n28.9\n0.6\n28.6\n0.7\n23.1\n1.4\n28.8\n1.1\n34.2\n0.2\n24.6\n-1.9\n\n\nNov-23\n29.2\n2.7\n30.4\n4.3\n27.5\n0.4\n29.8\n0.8\n29.2\n1.0\n30.9\n7.0\n25.9\n-0.2\n30.6\n3.3\n26.4\n1.4\n\n\nDec-23\n29.7\n0.8\n30.9\n0.7\n27.9\n1.0\n28.8\n-0.7\n29.3\n0.1\n32.4\n1.8\n26.4\n1.8\n35.3\n3.8\n27.3\n0.0\n\n\nJan-24\n28.3\n1.8\n30.2\n1.8\n25.7\n1.9\n27.4\n2.8\n25.1\n2.3\n32.3\n1.1\n26.3\n1.4\n36.2\n2.0\n27.0\n1.5\n\n\nFeb-24\n23.1\n0.0\n24.9\n0.2\n20.5\n-0.3\n20.2\n-1.5\n19.0\n-1.1\n28.2\n1.5\n22.1\n0.6\n30.4\n-0.8\n18.7\n1.1\n\n\nMar-24\n20.7\n1.7\n21.9\n1.4\n19.0\n2.1\n16.6\n2.4\n17.1\n2.8\n25.8\n0.7\n21.0\n1.4\n25.9\n2.1\n14.8\n1.3\n\n\nApr-24\n17.3\n-0.4\n19.4\n-0.1\n14.5\n-0.9\n11.3\n-1.3\n9.5\n-2.6\n25.6\n0.8\n20.0\n0.8\n21.6\n-0.7\n13.9\n-0.7\n\n\nMay-24\n11.8\n-3.2\n14.3\n-2.8\n8.2\n-3.9\n2.2\n-6.3\n-0.1\n-7.4\n23.6\n-0.4\n17.2\n-0.4\n15.3\n-4.0\n9.9\n-2.5"
  },
  {
    "objectID": "myR/pdf_tables/index.html#saving-the-data-to-a-csv-file-and-excel-file",
    "href": "myR/pdf_tables/index.html#saving-the-data-to-a-csv-file-and-excel-file",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Saving the Data to a CSV File and Excel File",
    "text": "Saving the Data to a CSV File and Excel File\nFinally, we can save the cleaned data to a CSV file for future use.\n\nCode# Save the table to a CSV file\nwrite.csv(table_separated_df, \"table_separated_df.csv\", row.names = FALSE)\n# Save the table to an Excel file\nwritexl::write_xlsx(table_separated_df, \"table_separated_df.xlsx\")"
  },
  {
    "objectID": "myR/pdf_tables/index.html#conclusion",
    "href": "myR/pdf_tables/index.html#conclusion",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Conclusion",
    "text": "Conclusion\nIn this post, we demonstrated how to extract tables from PDF files using the tabulapdf package in R. We walked through the steps of loading necessary libraries, extracting tables from PDFs, converting them to data frames, cleaning the data, and finally saving it to a CSV file. This process can be very useful for extracting and analyzing data from PDF reports and documents."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zahid Asghar",
    "section": "",
    "text": "I am Professor at School of Economics, Quaid-i-Azam University, Islamabad. I have extensive background working with applied econometrics, development issues (food security, urban and health) and using advanced analytics to enable data stakeholders to make informed decisions. I have also served as Director, School of Economics, Registrar Quaid-i-Azam University, Islamabad and I am also member of Research Advisory Committee (RAC) of RASTA Competitive Grants Program for Policy-oriented Research.\nI recently expanded my skill set to include topics like Impact Evaluation Tools, Quarto, tidymodels, doing economics with R, and data visualization using animation and interactivity. I am passionate about skills for jobs now and in the future, Virtual learning with new educational accounting system. I am also learning how quantitative reasoning and logic with media , digital and data literacy may help to lead actionable initiatives to spot and call fake/nonsense news."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "myR/pakwheels/index.html",
    "href": "myR/pakwheels/index.html",
    "title": "Harnessing Data Analytics for Effective Governance in Pakistan: A Support, Not a Substitute",
    "section": "",
    "text": "Harnessing Data Analytics for Effective Governance in Pakistan: A Support, Not a Substitute\nGiven the intricate challenges confronting Pakistan, a nation with a population of two hundred and forty million, in the third decade of the 21st century, it is imperative to establish robust government analytics to enhance decision-making processes for senior leadership and bureaucracy. In today’s digital age, societal expectations are heightened, while government resources remain limited. Consequently, maximizing the efficiency of these resources is paramount in addressing development and other challenges. Data analytics provides a means for thorough examination and holistic understanding of issues, enabling governments to better cope with these challenges. As governments expand their scope of operations to cater to the needs of the masses, there is a growing need to bolster their capacity to measure and evaluate a wide array of activities. In the digital age, developing the capability to obtain, interpret, and efficiently employ data for informed decision-making is crucial for attaining developmental objectives. Early investment in data-driven policies is vital to maximize the use of resources and promptly pursue desired outcomes. The granularity of data will offer profound insights, enhancing the effectiveness of decision-making processes.\nIn our pursuit of a better future, it is important to not only focus on having the right data but also to make sense of complex information for public policy making to supplement/complement public policy making. Data analytics based on various data sources of data: administrative, public procurement, health, education, public sector development projects, and budget spending through visualization, automated reproducible reports, statistical analysis, program evaluation, and trend analysis is the need of the hour. Besides this empirical data analysis, text analysis of policy documents, regulations, and tenders based on topic modeling and policy focus using Machine Learning tools is also needed.\nThe private sector has utilized the full potential of data. Nonetheless, the public sector operates under distinct dynamics compared to the private sector, despite the significant benefits that data has brought to the latter. Therefore, it’s important to understand that it is not the case that everything is measurable or that everything which is measurable is of great importance for public policy. Secondly, it is not data but data that matters. Easy-to-measure indicators may lead to false alarms leaving real issues unattended. It is also needed to protect space for judgment, discretion, and deliberation because not everything that matters can be measured.\nMy philosophy is that measuring what matters is more important rather than working on what is measurable. Secondly, what analytics can do is strengthen the quality of conversations about how to improve public administration, rather than dictating managerial responses to specific analytics findings.\nAnalytics, in my opinion, should supplement/complement decision making of senior leadership and senior government officials’ practical and tacit knowledge. Data analytics can strengthen the quality of conversation about how to improve public administration, rather than forcing to adapt specific analytics findings. It will generate evidence for better conversation and thus decisions- about how to improve public administration, execute projects efficiently and effectively, how to monitor and evaluate different projects among many other things.\nAreas Needing Focus\nJustice: Using data to identify inefficiencies in the judicial process and recommend reforms.\nGovernance and Climate Change: Establishing links between governance practices and climate change mitigation and adaptation.\nInstitution Building: Strengthening public institutions by identifying weaknesses through data and proposing targeted improvements.\nPublic Procurement: Developing clear rules for procurement officers based on data to ensure better policy outcomes.\nMy vision for data analytics is rooted in the pursuit of a brighter future, where I prioritize not only acquiring the right data but also harnessing the power of complex information to enhance public policy making. I recognize the imperative need for data analytics across various sources such as administrative records, public procurement data, health and education statistics, and public sector development projects. Through visualization, automated reproducible reports, statistical analysis, program evaluation, and trend analysis, I aim to extract valuable insights that can inform and complement public policy decisions.\nIn addition to empirical data analysis, I understand the significance of text analysis of policy documents, regulations, and tenders using techniques such as topic modeling and machine learning. This comprehensive approach allows me to uncover hidden patterns, identify policy focus areas, and enhance decision-making processes.\nHowever, I acknowledge that the public sector operates under unique dynamics compared to the private sector. Therefore, I emphasize the importance of understanding that not everything is measurable, and I prioritize measuring what truly matters. My philosophy revolves around supplementing decision-making processes with data analytics while acknowledging the invaluable practical and tacit knowledge of senior leadership and government officials.\nBy integrating data analytics into decision-making processes, I aim to facilitate better conversations about improving public administration, project execution efficiency, monitoring and evaluation, and various other aspects of governance. Ultimately, my goal is to generate evidence that enhances the quality of decision-making and fosters continuous improvement in public administration practices.\nLeveraging the Data Revolution for Public Sector Benefit\nThe data revolution has immensely benefited the private sector, and the public sector has yet to fully realize these benefits. It is important to harness the power of high-quality data and government analytics to derive informed public policy, laying the foundation for effective governance in our data-driven world. This requires human capital in data analytics and data science to supplement/complement bureaucracy-backed public policies. As creative bureaucracy is a basic pillar of executing any government policies and has deep insight, there is a need to enhance their capacity to make the right sense of data from complex information.\nMy vision is to harness the power of high-quality data analytics to drive informed public policy, laying the groundwork for effective governance in our data-driven world. Recognizing data as the new oil, I understand its immense value in navigating the complexities of modern society and gaining evidence-based insights into pressing issues.\nAligned with my commitment to the Sustainable Development Goals (SDGs), I recognize the urgent need for comprehensive, accurate, disaggregated, and timely data. By leveraging data analytics, I aim to inform policy decisions, guide resource allocation, and ensure that interventions are precisely tailored to drive impactful progress towards sustainable development."
  },
  {
    "objectID": "myR/pdf_tables1/index.html#introduction",
    "href": "myR/pdf_tables1/index.html#introduction",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Introduction",
    "text": "Introduction\nIn the part 1 of extracting pdf tables, we discussed how to extract data from PDF files using the tabulapdf package in R. In this part, we will explore little more for extracting data from PDFs. We will also discuss how to handle more complex tables and extract data from PDFs.\nWe have same libraries as in the first part."
  },
  {
    "objectID": "myR/pdf_tables1/index.html#required-libraries",
    "href": "myR/pdf_tables1/index.html#required-libraries",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Required Libraries",
    "text": "Required Libraries\nI have tried tabulizer to install but not successful. I have come across tabulapdf package and find it very handy. To begin, we’ll need to install and load the necessary libraries. Here is the list of packages we’ll be using:\n\nrJava\ntabulapdf\npdftools\ntidyverse\n\nLet’s load these libraries in R.\n\nCodeSys.setenv(JAVA_HOME = \"C:/Program Files/Java/jdk-22\") ## One check is for one's system if required for running `rJava`\nlibrary(rJava)\nlibrary(tabulapdf)\nlibrary(pdftools)\nlibrary(tidyverse)"
  },
  {
    "objectID": "myR/pdf_tables1/index.html#extracting-tables-from-a-pdf",
    "href": "myR/pdf_tables1/index.html#extracting-tables-from-a-pdf",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Extracting Tables from a PDF",
    "text": "Extracting Tables from a PDF\nNow we will extract a table from page 10 from the same PDF file as in part 1. This PDF is a monthly report on Consumer Price Index from the Pakistan Bureau of Statistics.\n\nCode# URL of the monthly review PDF\nf1 &lt;- \"https://www.pbs.gov.pk/sites/default/files/price_statistics/cpi/may/Monthly%20Review%20May%2C%202024.pdf\"\n\n\n\n\n\n\n\nFigure 1: Consumer Price Index (National) by Group of Commodities and Services (Base 2015-16)\n\n\nOne can see from Figure 1 that the table we want to extract is on the third page of the PDF. Let’s extract the table from the third page of the PDF file.\n\nCode# Extract and view the table from the third page of the PDF\nextract_tables(f1, pages =8 )[[1]] |&gt; kableExtra::kable() |&gt; kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F)\n\n\nTable 1: Extracted Table from the PDF\n\n\n\n\n\nTable 1: Consumer Price Index (National) by Group of Commodities and Services (Base 2015-16)\n\n\n\n% Change Impact\n\n\nGroup Indices May 2024 (In % points)\n\n\nGroup Weight Over May 2024 Over\n\n\nNo (%)\n\n\nMay 24 April 24 May 23 April 24 May 23 April 24 May 23\n\n\nGeneral 100.00 254.78 263.32 227.96 -3.24 11.76 -3.24 11.76\n\n\n1. Food & Non-alcoholic Bev. 34.58 264.01 286.43 264.45 -7.83 -0.17 -2.94 -0.07\n\n\nNon-perishable Food Items 29.60 266.43 282.07 271.20 -5.54 -1.76 -1.76 -0.62\n\n\nPerishable Food Items 4.99 249.59 312.36 224.41 -20.10 11.22 -1.19 0.55\n\n\n2. Alcoholic Bev. & Tobacco 1.02 366.68 366.07 356.40 0.17 2.88 0.00 0.05\n\n\n3. Clothing & Footwear 8.60 239.46 238.38 202.95 0.46 17.99 0.04 1.38\n\n\nHousing, Water, Electricity,\n\n\n4. 23.63 236.63 239.81 177.92 -1.33 33.00 -0.29 6.08\n\n\nGas & Fuels\n\n\nFurnishing & Household\n\n\n5. 4.10 267.41 266.41 235.09 0.37 13.75 0.02 0.58\n\n\nEquipment Maintenance\n\n\n6. Health 2.79 241.17 237.29 201.94 1.63 19.42 0.04 0.48\n\n\n7. Transport 5.91 315.06 320.28 285.36 -1.63 10.41 -0.12 0.77\n\n\n8. Communication 2.21 134.27 134.85 118.27 -0.43 13.53 0.00 0.16\n\n\n9. Recreation & Culture 1.59 262.27 258.77 242.93 1.35 7.96 0.02 0.13\n\n\n10. Education 3.79 199.00 196.20 171.63 1.43 15.95 0.04 0.45\n\n\n11. Restaurants & Hotels 6.92 267.22 269.38 235.03 -0.80 13.70 -0.06 0.98\n\n\n12. Miscellaneous 4.87 282.79 282.22 246.64 0.20 14.66 0.01 0.77\n\n\n\n\n\n\n\n\n\n\n\nTable 1 is extracted from the PDF file in the same way as in Part 1. But all the data is in one column. One can adjust it as per requirement by some more coding. But we are showing an easy way to extract such data. We shall use first command get_page_dims to get the dimensions of the page and then use area to extract the table.\n\nCodeget_page_dims(f1, pages = 8)\n\n[[1]]\n[1] 595.32 841.92\n\n\nAfter getting page dimensions, we can extract the table by specifying the area of the table. One has to do some minor adjustments to get the desired table by specifying four values top, left, bottom, and right.\n\nCodelibrary(data.table)\nData1 &lt;-\n  extract_tables(\n    file  = f1\n    , pages = 8\n    , area  = list(c(180, 84, 470, 855)) # (top, left, bottom, right)\n    , guess = FALSE\n  ) [[1]] %&gt;%\n  as.data.table()\n\nData1 |&gt; kableExtra::kable() |&gt; kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F) \n\n\nTable 2: Extracted Table from the PDF with specified area\n\n\n\n\n\n...1\n...2\nMay 24\nApril 24...4\nMay 23...5\nApril 24...6\nMay 23...7\nApril 24...8\nMay 23...9\n\n\n\nGeneral\n100.00\n254.78\n263.32\n227.96\n-3.24\n11.76\n-3.24\n11.76\n\n\nFood & Non-alcoholic Bev.\n34.58\n264.01\n286.43\n264.45\n-7.83\n-0.17\n-2.94\n-0.07\n\n\nNon-perishable Food Items\n29.60\n266.43\n282.07\n271.20\n-5.54\n-1.76\n-1.76\n-0.62\n\n\nPerishable Food Items\n4.99\n249.59\n312.36\n224.41\n-20.10\n11.22\n-1.19\n0.55\n\n\nAlcoholic Bev. & Tobacco\n1.02\n366.68\n366.07\n356.40\n0.17\n2.88\n0.00\n0.05\n\n\nClothing & Footwear\n8.60\n239.46\n238.38\n202.95\n0.46\n17.99\n0.04\n1.38\n\n\nHousing, Water, Electricity,\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nNA\n23.63\n236.63\n239.81\n177.92\n-1.33\n33.00\n-0.29\n6.08\n\n\nGas & Fuels\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nFurnishing & Household\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nNA\n4.10\n267.41\n266.41\n235.09\n0.37\n13.75\n0.02\n0.58\n\n\nEquipment Maintenance\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nHealth\n2.79\n241.17\n237.29\n201.94\n1.63\n19.42\n0.04\n0.48\n\n\nTransport\n5.91\n315.06\n320.28\n285.36\n-1.63\n10.41\n-0.12\n0.77\n\n\nCommunication\n2.21\n134.27\n134.85\n118.27\n-0.43\n13.53\n0.00\n0.16\n\n\nRecreation & Culture\n1.59\n262.27\n258.77\n242.93\n1.35\n7.96\n0.02\n0.13\n\n\nEducation\n3.79\n199.00\n196.20\n171.63\n1.43\n15.95\n0.04\n0.45\n\n\nRestaurants & Hotels\n6.92\n267.22\n269.38\n235.03\n-0.80\n13.70\n-0.06\n0.98\n\n\nMiscellaneous\n4.87\n282.79\n282.22\n246.64\n0.20\n14.66\n0.01\n0.77\n\n\n\n\n\n\n\n\n\n\n\nTable 2 is almost the same as reported in Figure 1 unlike Table 1 which has all data in one column. However, some adjustments are still required. We have first column names with some specific symbols so its names are spread in more than one rows. To remove rows with NAs and adjusting row names, we can do some wrangling.\n\nCodecolnames(Data1) &lt;- c(\"Group\", \" Group Weight\", \"index_may_2024\", \"index_apr_2024\", \"index_may_2023\", \"index_may_2024_mom\", \"index_may_2024_yoy\",\n                      \"impact_apr_2024\", \"impact_may_2023\")\nData2 &lt;- Data1 %&gt;%\n  mutate(\n    Group = case_when(\n      is.na(Group) & row_number() == 8 ~ \"Housing, Water, Electricity, Gas & Other\",\n      is.na(Group) & row_number() == 11 ~ \"Furnishing & Household Equip. & Maintenance\",\n      TRUE ~ Group\n    )\n  )\n\n\n\nCode## Remove rows with missing values\n\nData3 &lt;- Data2 |&gt; drop_na()\n\n## Cleaned Data Frame\nData3 |&gt; kableExtra::kable() |&gt; kableExtra::kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = F) \n\n\nTable 3: Cleaned Data Frame\n\n\n\n\n\nGroup\nGroup Weight\nindex_may_2024\nindex_apr_2024\nindex_may_2023\nindex_may_2024_mom\nindex_may_2024_yoy\nimpact_apr_2024\nimpact_may_2023\n\n\n\nGeneral\n100.00\n254.78\n263.32\n227.96\n-3.24\n11.76\n-3.24\n11.76\n\n\nFood & Non-alcoholic Bev.\n34.58\n264.01\n286.43\n264.45\n-7.83\n-0.17\n-2.94\n-0.07\n\n\nNon-perishable Food Items\n29.60\n266.43\n282.07\n271.20\n-5.54\n-1.76\n-1.76\n-0.62\n\n\nPerishable Food Items\n4.99\n249.59\n312.36\n224.41\n-20.10\n11.22\n-1.19\n0.55\n\n\nAlcoholic Bev. & Tobacco\n1.02\n366.68\n366.07\n356.40\n0.17\n2.88\n0.00\n0.05\n\n\nClothing & Footwear\n8.60\n239.46\n238.38\n202.95\n0.46\n17.99\n0.04\n1.38\n\n\nHousing, Water, Electricity, Gas & Other\n23.63\n236.63\n239.81\n177.92\n-1.33\n33.00\n-0.29\n6.08\n\n\nFurnishing & Household Equip. & Maintenance\n4.10\n267.41\n266.41\n235.09\n0.37\n13.75\n0.02\n0.58\n\n\nHealth\n2.79\n241.17\n237.29\n201.94\n1.63\n19.42\n0.04\n0.48\n\n\nTransport\n5.91\n315.06\n320.28\n285.36\n-1.63\n10.41\n-0.12\n0.77\n\n\nCommunication\n2.21\n134.27\n134.85\n118.27\n-0.43\n13.53\n0.00\n0.16\n\n\nRecreation & Culture\n1.59\n262.27\n258.77\n242.93\n1.35\n7.96\n0.02\n0.13\n\n\nEducation\n3.79\n199.00\n196.20\n171.63\n1.43\n15.95\n0.04\n0.45\n\n\nRestaurants & Hotels\n6.92\n267.22\n269.38\n235.03\n-0.80\n13.70\n-0.06\n0.98\n\n\nMiscellaneous\n4.87\n282.79\n282.22\n246.64\n0.20\n14.66\n0.01\n0.77\n\n\n\n\n\n\n\n\n\n\n\nTable 3 is the cleaned data frame. We have adjusted column names and removed rows with missing values. One can use columns names as per one’s requirement."
  },
  {
    "objectID": "myR/pdf_tables1/index.html#saving-the-data-to-a-csv-file-and-excel-file",
    "href": "myR/pdf_tables1/index.html#saving-the-data-to-a-csv-file-and-excel-file",
    "title": "Extracting Data from PDFs documents using tabulapdf in R",
    "section": "Saving the Data to a CSV File and Excel File",
    "text": "Saving the Data to a CSV File and Excel File\nFinally, we can save the cleaned data to a CSV and excel file for future use.\n\nCodewrite.csv(Data3, \"CPI.csv\", row.names = FALSE)\nwritexl::write_xlsx(Data3, \"CPI.xlsx\")"
  },
  {
    "objectID": "posts/AI NEEDS YOU by Verity Herding/index.html",
    "href": "posts/AI NEEDS YOU by Verity Herding/index.html",
    "title": "AI NEEDS YOU: A THOUGHT-PROVOKING EXPLORATION OF ARTIFICIAL INTELLIGENCE",
    "section": "",
    "text": "Verity Herding’s AI Needs You offers a thought-provoking and comprehensive exploration of the rapid advancements and complex ethical dilemmas presented by artificial intelligence. The book is both a thrilling and alarming dive into AI’s potential, showcasing its remarkable breakthroughs and the significant concerns it raises.\nHerding begins by highlighting the unprecedented speed at which AI researchers, armed with vast data and computational power, are achieving breakthroughs. These advancements have the potential to revolutionize various fields, from accurately diagnosing diseases to analyzing vast amounts of text data for profound insights. However, this great promise is tempered by the potential for unethical, disturbing, and dangerous uses of AI technology.\nA critical section of the book addresses the ethical dilemmas posed by AI. Herding points out the troubling frequency of mistakes in facial recognition technology, which disproportionately affect black and brown races, leading to serious consequences such as the wrongful victimization of innocent people. She also critiques Amazon for treating its workers like robots under stringent monitoring systems, overlooking the human aspect of their labor. This underscores the urgent need for ethical AI deployment and active involvement in shaping its future.\nAI: A Reflection of Human Flaws and Aspirations\nArtificial Intelligence, whether superintelligent or God-like, is ultimately a human creation and thus inherits human flaws as well as their brilliance. Herding argues for the urgent need to harness AI for humanity’s benefit, warning that it might otherwise become a danger. Technologies developed by humans reflect both their aspirations and their imperfections, revealing both our disappointments and darker aspects over time.\nEvolving Demands and AI’s Power Players\nThe demand for science and technology evolves over time. In different eras, sea travel, communication, and oil were pivotal. Now, it is computer science. AI is predominantly controlled by powerful entities driven by profit motives. Herding emphasizes that this concentration of AI development in the hands of private giants, rather than under government control as in past scientific developments, could lead to serious repercussions. Silicon Valley grapples with cultural issues, where women and underrepresented groups often face challenges, leading to a decline in trust and an increase in greed.\nThe Political Nature of Technological Advancement\nTechnological development is inherently political, with preferences changing over time. Major advancements, like the internet, required substantial effort. Steering AI in the right direction will necessitate tremendous work from the government, technology companies, and the public. The US moon landing missions were politically motivated, debunking the notion that science is neutral. Similarly, AI’s development is influenced by geopolitical interests, with China and the US racing for dominance.\nAI: From Benefits to National Security Concerns\nAI is globally seen as a peaceful and aspiring technology, but unlike government-regulated programs, its direction is dominated by private giants. China’s goal to lead in AI by 2030 and the US’s competitive stance highlight the concept of an “AI arms race,” shifting the focus from AI’s benefits and risks to its potential as a tool for national security. AI has been used for defense purposes, and its misuse, such as in Gaza, demands immediate intervention.\nMilitary and Economic AI: The New Geopolitical Battlefield\nAI is a new geopolitical field that must be won, leading to techno-nationalism. The Sino-US race for AI dominance involves a pursuit of superior technology without corresponding efforts to shape global norms. AI is viewed primarily as a means of national interest and competition, with little imagination beyond these constraints.\nThe Need for International Cooperation\nHerding uses the IVF debate as a parallel to illustrate the necessity of societal acceptance for scientific advancements. The human egg donation debate, a significant aspect of IVF, raised numerous ethical issues, prompting the UK government to form specialized committees to address these concerns. One notable outcome was the establishment of the 14-day rule, which set ethical boundaries for embryo research. This historical example underscores the importance of regulatory frameworks and societal consensus in guiding scientific progress, a principle that Herding argues is equally crucial for the responsible development and deployment of AI technologies.\nPublic Acceptance and Disruption\nPublic acceptance and disruption in science are necessary, Herding argues, and she raises concerns about AI technologies being captured by a corporate mindset. The book also addresses the issue of AI-generated images being weaponized, as seen in Pakistan, where fake images are used for propaganda.\nThe Role of Experts and Regulation\nHandling these issues is challenging, and some limitations on AI technology use are necessary. A committee of trusted experts should make sensible decisions regarding AI technology. She advocates for compromise, humility, and the acceptance of diverse viewpoints, qualities she finds lacking in the tech industry. The book critiques the concentration of AI development within private companies, which creates proprietary technologies that cannot be easily scrutinized, leading to a dangerous power imbalance.\nThe Influence of Powerful Entities\nPowerful entities with vast resources develop AI that benefits their own values and services, creating a dangerous power imbalance. This alters the character of AI itself. Opposition to what higher education has become, a factory treating students like data, mirrors concerns about AI development.\nThe Impact of Technology on Society\nTechnology drives economic growth and expands opportunities. However, the concentration of wealth and power in the tech industry raises concerns about its impact on democracy and society. Regulation and oversight are crucial to ensure AI benefits all, not just the powerful few.\nConclusion\nAI Needs You by Verity Herding is a compelling and insightful exploration of AI’s potential and the ethical, societal, and political challenges it presents. Herding’s arguments are well-researched and thought-provoking, making the book a must-read for anyone interested in the future of artificial intelligence and its impact on humanity. The book is a call to action, urging readers to engage actively in shaping AI’s future to ensure it benefits humanity as a whole while maintaining ethical standards."
  },
  {
    "objectID": "posts/AI NEEDS YOU by Verity Herding/index.html#ai-needs-you-a-thought-provoking-exploration-of-artificial-intelligence",
    "href": "posts/AI NEEDS YOU by Verity Herding/index.html#ai-needs-you-a-thought-provoking-exploration-of-artificial-intelligence",
    "title": "AI NEEDS YOU: A THOUGHT-PROVOKING EXPLORATION OF ARTIFICIAL INTELLIGENCE",
    "section": "",
    "text": "Verity Herding’s AI Needs You offers a thought-provoking and comprehensive exploration of the rapid advancements and complex ethical dilemmas presented by artificial intelligence. The book is both a thrilling and alarming dive into AI’s potential, showcasing its remarkable breakthroughs and the significant concerns it raises.\nHerding begins by highlighting the unprecedented speed at which AI researchers, armed with vast data and computational power, are achieving breakthroughs. These advancements have the potential to revolutionize various fields, from accurately diagnosing diseases to analyzing vast amounts of text data for profound insights. However, this great promise is tempered by the potential for unethical, disturbing, and dangerous uses of AI technology.\nA critical section of the book addresses the ethical dilemmas posed by AI. Herding points out the troubling frequency of mistakes in facial recognition technology, which disproportionately affect black and brown races, leading to serious consequences such as the wrongful victimization of innocent people. She also critiques Amazon for treating its workers like robots under stringent monitoring systems, overlooking the human aspect of their labor. This underscores the urgent need for ethical AI deployment and active involvement in shaping its future.\nAI: A Reflection of Human Flaws and Aspirations\nArtificial Intelligence, whether superintelligent or God-like, is ultimately a human creation and thus inherits human flaws as well as their brilliance. Herding argues for the urgent need to harness AI for humanity’s benefit, warning that it might otherwise become a danger. Technologies developed by humans reflect both their aspirations and their imperfections, revealing both our disappointments and darker aspects over time.\nEvolving Demands and AI’s Power Players\nThe demand for science and technology evolves over time. In different eras, sea travel, communication, and oil were pivotal. Now, it is computer science. AI is predominantly controlled by powerful entities driven by profit motives. Herding emphasizes that this concentration of AI development in the hands of private giants, rather than under government control as in past scientific developments, could lead to serious repercussions. Silicon Valley grapples with cultural issues, where women and underrepresented groups often face challenges, leading to a decline in trust and an increase in greed.\nThe Political Nature of Technological Advancement\nTechnological development is inherently political, with preferences changing over time. Major advancements, like the internet, required substantial effort. Steering AI in the right direction will necessitate tremendous work from the government, technology companies, and the public. The US moon landing missions were politically motivated, debunking the notion that science is neutral. Similarly, AI’s development is influenced by geopolitical interests, with China and the US racing for dominance.\nAI: From Benefits to National Security Concerns\nAI is globally seen as a peaceful and aspiring technology, but unlike government-regulated programs, its direction is dominated by private giants. China’s goal to lead in AI by 2030 and the US’s competitive stance highlight the concept of an “AI arms race,” shifting the focus from AI’s benefits and risks to its potential as a tool for national security. AI has been used for defense purposes, and its misuse, such as in Gaza, demands immediate intervention.\nMilitary and Economic AI: The New Geopolitical Battlefield\nAI is a new geopolitical field that must be won, leading to techno-nationalism. The Sino-US race for AI dominance involves a pursuit of superior technology without corresponding efforts to shape global norms. AI is viewed primarily as a means of national interest and competition, with little imagination beyond these constraints.\nThe Need for International Cooperation\nHerding uses the IVF debate as a parallel to illustrate the necessity of societal acceptance for scientific advancements. The human egg donation debate, a significant aspect of IVF, raised numerous ethical issues, prompting the UK government to form specialized committees to address these concerns. One notable outcome was the establishment of the 14-day rule, which set ethical boundaries for embryo research. This historical example underscores the importance of regulatory frameworks and societal consensus in guiding scientific progress, a principle that Herding argues is equally crucial for the responsible development and deployment of AI technologies.\nPublic Acceptance and Disruption\nPublic acceptance and disruption in science are necessary, Herding argues, and she raises concerns about AI technologies being captured by a corporate mindset. The book also addresses the issue of AI-generated images being weaponized, as seen in Pakistan, where fake images are used for propaganda.\nThe Role of Experts and Regulation\nHandling these issues is challenging, and some limitations on AI technology use are necessary. A committee of trusted experts should make sensible decisions regarding AI technology. She advocates for compromise, humility, and the acceptance of diverse viewpoints, qualities she finds lacking in the tech industry. The book critiques the concentration of AI development within private companies, which creates proprietary technologies that cannot be easily scrutinized, leading to a dangerous power imbalance.\nThe Influence of Powerful Entities\nPowerful entities with vast resources develop AI that benefits their own values and services, creating a dangerous power imbalance. This alters the character of AI itself. Opposition to what higher education has become, a factory treating students like data, mirrors concerns about AI development.\nThe Impact of Technology on Society\nTechnology drives economic growth and expands opportunities. However, the concentration of wealth and power in the tech industry raises concerns about its impact on democracy and society. Regulation and oversight are crucial to ensure AI benefits all, not just the powerful few.\nConclusion\nAI Needs You by Verity Herding is a compelling and insightful exploration of AI’s potential and the ethical, societal, and political challenges it presents. Herding’s arguments are well-researched and thought-provoking, making the book a must-read for anyone interested in the future of artificial intelligence and its impact on humanity. The book is a call to action, urging readers to engage actively in shaping AI’s future to ensure it benefits humanity as a whole while maintaining ethical standards."
  },
  {
    "objectID": "posts/data_science_subcontinent/index.html",
    "href": "posts/data_science_subcontinent/index.html",
    "title": "Spicing Up Data Science: A Delicious Blend of Analytics and Gourmet Delights",
    "section": "",
    "text": "Basics of data science with food 101 dataset\nIn this analysis, we used the Indian Food 101 dataset from Kaggle (Prabhavalkar 2023).I will this data rathat I call it subcontinent Food dataset, using from very basics of data handling, analysis, and visualization techniques with R and the Tidyverse suite. The dataset contains information about various Indian dishes, their ingredients, dietary preferences, and preparation times. We will explore the dataset to understand the distribution of dishes by course, flavor profile, and diet type. We will also analyze the preparation and cooking times of the dishes and identify the most common ingredients used in Indian cuisine. Click here to read more\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Future jobs and universities role/index.html",
    "href": "posts/Future jobs and universities role/index.html",
    "title": "Future jobs and universities",
    "section": "",
    "text": "World has been changing very fast due to the digital revolution and other technological changes. Covid-19 disruption has accelerated the pace of penetration of digital technologies, artificial intelligence and machine learning even in the lives of common people. After Covid-19 pandemic many jobs have either become obsolete or at least require a new/updated set of skills to continue one's job. Many workers will never regain their pre-covid jobs as those jobs will never be back in the market and many new post-covid jobs skills may be more challenging and or different in nature. Fast technological changes have made so many new jobs available. What are skills required for future jobs is a question whose answer is not known to anyone because there are a large number of future jobs which don't exist yet. What is a way forward in such a situation? This requires deep introspection and integrated thinking about the learning model to be adopted. \nMoreover, life expectancy has been increasing by two to three years with each decade in the past two centuries. It is expected that life expectancy of people born in the next 30 years may reach 150 years. With increased life expectancy and work life spanning over 50 to 80 years , there will be a remote possibility that one enters a job and retires from there. One has to switch more than a dozen jobs in one's life span. Each job will have a somewhat different nature of skills, so one can be in the job market only if one is continuously updating one's skills.\nDue to increased life expectancy, one has to re-imagine LEARN, EARN AND REST to LEARN and EARN, LEARN and EARN, and LEARN and EARN… This continuously changing nature of job skills demands that one has to adapt oneself in a continuous learning mode to meet future challenges. \n According to Sohail Inayatullah (futurist), often organizations think when some disruption happens or they miss something. Futuristic thinking means that working on problems before some structural change makes one redundant. According to him, often people think about the future, it is out there- Robotic, Space travel, etc. Future is not like an empty space, it is like the past. It is an active aspect of the present and thinking about the future is to change as today.\nNow the question is: are there such opportunities of continuously improving one's skills or learning new skills? Many jobs still prefer a degree and ask what one knows rather than what one can do. To resolve the issue of having a degree for those who have skills, are we ready for part time learning opportunities in our universities and colleges? This will help millions who have the skills but are unable to get decent jobs because the degree signaling effect is very strong. Are there programs available where one can learn new skills while staying on job? Will our universities serve those who are unserved?\nEven if our graduates are well trained and have requisite skills for the job market, there is a skill gap emerging overtime due to technological advances. As a result either they will become less productive or unemployed altogether. Currently, there are very limited opportunities available for upskilling.\nMoreover, who will cater the needs of burgeoning youth who didn’t get opportunities for higher education either due to high cost of education or due to somehow getting lower scores in some class(es) and did not secure a seat. These fundamental questions need to be addressed at national, provincial, regional and university level.\nHow is our education system taking up this pace of technology change? Are we preparing children for jobs of the future and kinds of industry and economy within that when they leave college/university? Jeremy Howard (data scientist and AI) says not at all. He says its sad that basic computer skills and basic data analysis tools are not taught the way it should be even in the US.In her book Long Life Learning: Preparing for Jobs that Don't Even Exist Yet ,Michelle R. Weise asks for developing a comprehensive Learning Ecosystem and to shift goal posts from TIME as fixed and LEARNING as variable to keep LEARNING fixed and TIME as variable. When LEARNING will be fixed then it will not matter whether its online platform or Physical (full time/part time) as one can’t go to the next step unless one has those pre-requisite skills. She also emphasizes that the university learning ecosystem should enable graduates to start moving on a continuous learning path rather than simply focusing on imparting certain skills. It’s a very timely book providing enough food for thought for all of us to rethink our higher education system to meet the challenges of new technologies\nPakistan has a youth bulge and economic growth is not sufficient to absorb it in the labor force market. On the positive aspect, due to digital technologies many jobs have become global in nature. How can one compete in a fast changing domestic and global market in the Silicon Valley era? Traditional university education system is misaligned with the current job market and simply adding a technological learning management system to it will not resolve the issue. The future of both higher education and jobs is uncertain, and many potential futures exist. In order to move from a future we don’t want to move to a future we want, we have to think and practice boldly.\nIn her book Long Life Learning: Preparing for Jobs that Don't Even Exist Yet ,Michelle R. Weise highlights that due to the fast changing world and due to rapid emergence and penetration of digital technologies, artificial intelligence, Machine Learning among many others, there is a need to develop a new learning ecosystem. This book is written mainly for a country like the United States but these points are equally important for low income countries like Pakistan."
  },
  {
    "objectID": "posts/Future jobs and universities role/index.html#future-jobs",
    "href": "posts/Future jobs and universities role/index.html#future-jobs",
    "title": "Future jobs and universities",
    "section": "",
    "text": "World has been changing very fast due to the digital revolution and other technological changes. Covid-19 disruption has accelerated the pace of penetration of digital technologies, artificial intelligence and machine learning even in the lives of common people. After Covid-19 pandemic many jobs have either become obsolete or at least require a new/updated set of skills to continue one's job. Many workers will never regain their pre-covid jobs as those jobs will never be back in the market and many new post-covid jobs skills may be more challenging and or different in nature. Fast technological changes have made so many new jobs available. What are skills required for future jobs is a question whose answer is not known to anyone because there are a large number of future jobs which don't exist yet. What is a way forward in such a situation? This requires deep introspection and integrated thinking about the learning model to be adopted. \nMoreover, life expectancy has been increasing by two to three years with each decade in the past two centuries. It is expected that life expectancy of people born in the next 30 years may reach 150 years. With increased life expectancy and work life spanning over 50 to 80 years , there will be a remote possibility that one enters a job and retires from there. One has to switch more than a dozen jobs in one's life span. Each job will have a somewhat different nature of skills, so one can be in the job market only if one is continuously updating one's skills.\nDue to increased life expectancy, one has to re-imagine LEARN, EARN AND REST to LEARN and EARN, LEARN and EARN, and LEARN and EARN… This continuously changing nature of job skills demands that one has to adapt oneself in a continuous learning mode to meet future challenges. \n According to Sohail Inayatullah (futurist), often organizations think when some disruption happens or they miss something. Futuristic thinking means that working on problems before some structural change makes one redundant. According to him, often people think about the future, it is out there- Robotic, Space travel, etc. Future is not like an empty space, it is like the past. It is an active aspect of the present and thinking about the future is to change as today.\nNow the question is: are there such opportunities of continuously improving one's skills or learning new skills? Many jobs still prefer a degree and ask what one knows rather than what one can do. To resolve the issue of having a degree for those who have skills, are we ready for part time learning opportunities in our universities and colleges? This will help millions who have the skills but are unable to get decent jobs because the degree signaling effect is very strong. Are there programs available where one can learn new skills while staying on job? Will our universities serve those who are unserved?\nEven if our graduates are well trained and have requisite skills for the job market, there is a skill gap emerging overtime due to technological advances. As a result either they will become less productive or unemployed altogether. Currently, there are very limited opportunities available for upskilling.\nMoreover, who will cater the needs of burgeoning youth who didn’t get opportunities for higher education either due to high cost of education or due to somehow getting lower scores in some class(es) and did not secure a seat. These fundamental questions need to be addressed at national, provincial, regional and university level.\nHow is our education system taking up this pace of technology change? Are we preparing children for jobs of the future and kinds of industry and economy within that when they leave college/university? Jeremy Howard (data scientist and AI) says not at all. He says its sad that basic computer skills and basic data analysis tools are not taught the way it should be even in the US.In her book Long Life Learning: Preparing for Jobs that Don't Even Exist Yet ,Michelle R. Weise asks for developing a comprehensive Learning Ecosystem and to shift goal posts from TIME as fixed and LEARNING as variable to keep LEARNING fixed and TIME as variable. When LEARNING will be fixed then it will not matter whether its online platform or Physical (full time/part time) as one can’t go to the next step unless one has those pre-requisite skills. She also emphasizes that the university learning ecosystem should enable graduates to start moving on a continuous learning path rather than simply focusing on imparting certain skills. It’s a very timely book providing enough food for thought for all of us to rethink our higher education system to meet the challenges of new technologies\nPakistan has a youth bulge and economic growth is not sufficient to absorb it in the labor force market. On the positive aspect, due to digital technologies many jobs have become global in nature. How can one compete in a fast changing domestic and global market in the Silicon Valley era? Traditional university education system is misaligned with the current job market and simply adding a technological learning management system to it will not resolve the issue. The future of both higher education and jobs is uncertain, and many potential futures exist. In order to move from a future we don’t want to move to a future we want, we have to think and practice boldly.\nIn her book Long Life Learning: Preparing for Jobs that Don't Even Exist Yet ,Michelle R. Weise highlights that due to the fast changing world and due to rapid emergence and penetration of digital technologies, artificial intelligence, Machine Learning among many others, there is a need to develop a new learning ecosystem. This book is written mainly for a country like the United States but these points are equally important for low income countries like Pakistan."
  },
  {
    "objectID": "posts/Minimizing nonsense/index.html",
    "href": "posts/Minimizing nonsense/index.html",
    "title": "Understanding and minimizing nonsense in digital world",
    "section": "",
    "text": "Please find my talk on Understand and minimizing nonsense in digital world at IPRI data science workshop by [atomcamp](https://atomcamp.com)\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/propensity_score_matching/index.html",
    "href": "posts/propensity_score_matching/index.html",
    "title": "Propensity Score Matching for Causal Inference",
    "section": "",
    "text": "PSM methods including entropic balancing for causal inference\nCausal inference is a critical aspect of research in fields such as economics, public health, and social sciences. One of the primary challenges in causal inference is estimating the effect of a treatment or intervention on an outcome variable while accounting for potential confounding variables. Conducting Randomized Controlled Trials (RCTs) is considered the gold standard for estimating causal effects. However, in many cases, researchers rely on observational data, where treatment assignment is not random, leading to potential bias in the estimated treatment effect. Propensity score matching is a widely used method to address this issue by balancing covariates between treatment and control groups, thereby reducing bias and improving the validity of causal inference. Propensity score matching (PSM) is a statistical technique designed to address this challenge by accounting for covariates that predict receiving the treatment, making it particularly useful in observational studies where random assignment is not feasible. In this tutorial, I will demonstrate how to perform propensity score matching using various methods in R, highlight the advantages of entropic balancing, and provide a step-by-step guide to assessing balance diagnostics and estimating treatment effects with matched data. This comprehensive guide aims to equip researchers with the necessary tools to conduct robust causal inference using observational data. Click here to read more\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Talk/index.html",
    "href": "posts/Talk/index.html",
    "title": "How to be an effective teacher",
    "section": "",
    "text": "Please find my talk on How to be an effective teacher at Muzaffarabad for college teachers.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Inferential Statistics\nQuantitative Methods for Development Economics\nEconometrics 2022"
  },
  {
    "objectID": "teaching.html#courses-2022-23",
    "href": "teaching.html#courses-2022-23",
    "title": "Teaching",
    "section": "",
    "text": "Inferential Statistics\nQuantitative Methods for Development Economics\nEconometrics 2022"
  }
]